# All right.

All right. Project brief. Goal. Build [[Zeddal]], a standalone cross-platform knowledge app, desktop first, mobile later, that feels familiar to Obsidian, but adds voice first capture with live translation and summarization, atomic Zettelcast and notes, graph view, robust search, beyond Wikilinks, Wikilinks and Backlinks, and export to Notion, Obsidian, OneNote, Google Docs, et cetera. Key differentiator is that it needs to be able to handle 25 to 45 minutes of rambling recording and reliably summarize segment and link into atomic notes, cross-referenced to existing lectures and notes, searchable in a vault. Inputs you can now use. You can use a source repo, and I'm going to provide that repo, Figma file for the UI. This is a rough sketch, but we can add a different feel for different tenants, whether that be the Department of Defense, Department of Justice, medical facilities or institutions or the education sector. The current infrastructure that I plan to utilize in the cloud is SupaBase for auth, PostgreSQL, storage, edge functions, Vercel for web and edge adapters. The domain is a domain that I will own and attach that paid domain to Vercel. Compliance, this must be school district friendly, whether that be FERPA or COPPA posture, SSO options, data minimization, audit logs and accessibility. Platforms, runtime and monorepo. Desktop phase one or the minimally viable product is going to be a Tori and React plus TypeScript. It's a lightweight, secure and native menus, system mic access, shared core for domain logic, note model, graph index, chunker, linker, exports. We're going to use that for the voice and transcription mechanics of the vocal recorder. Web companion, this is going to be a Next.js 15 plus React or Vercel for accounting, billing, web read only access and cloud vault browsing. Google is going to be Expo React native targeting iOS and Android. Reuse the packages core found within the Git repo. I would also like a little bit of, or I would like key cross platform support for Chromebooks. The build system, Turbo repo with PMPM workspaces, styling is going to be a combination of Tailwind and Radix UI, Figma tokens via app token studio. Graph rendering will be D3 tech force, desktop and web and then React spring for interactions. Codex and Claude create monorepo like forward slash apps. This will be a code platform for bash. Forward slash apps, forward slash ZettelTAC desktop. Parentheses Tori plus React, end parentheses. Forward slash ZettelTAC web. Parentheses Next.js on Vercel, close parentheses. Forward slash ops. Parentheses infra comma CI comma scripts, close parentheses. Forward slash packages. Forward slash core, domain models, chunking, linkers, exporters, search adapters, et cetera. UI design system sync from Figma tokens. Forward slash speech, capture, VAD, segmentation, streaming, STT, configs, ES lint, TS config, Tailwind, Jest and Playwright. Increase to note pipeline. This is a critical path. Requirements. You need to be able to handle 25 to 45 minute recordings with streaming, live translation, live summarization and post talk refinement. The pipeline stages. Capture is going to be at packages forward slash speech. Uses system mic input, VAD, web RTC to VAD or Solero. Requirements to local Whisper C++ for on device STT, fallback, hosted Whisper ASR, language, user select source target, perform live translation track in parallel, subtitle line stream, chunking, online segmentation by pause plus semantic boundary, store interim segments. Summarization, streaming, rolling, bullet, summary, every end tokens. After stop, run refinement pass over a full transcript. Atomic note synthesis split into atomic ZETLs, Z-E-D-D-A-L-S, with unique IDs, title, claim, context, source and tags. Linking, lexical wiki link. That'll be a double bracket, note title, double back bracket, close detection. Semantic, vector similarity. So, local SQLite, FTS5 plus SQLite, TACVSS, cloud PG vector and super base to link to existing notes and lectures. The graph index will be an update bidirectional edges with backlinks, topic clusters and time anchors. The time anchor is going to be utilized to be able to tell when a note was referenced and we can use that to ensure that any note that was captured in a singular lecture will be back referenced to a specific time stamp. Persist to local vault, markdown plus front matter plus JSON index and cloud vault, super base storage plus postgres metadata. Search, hybrid keyword FTS plus vector, filters, data source, tags and speakers. Acceptance targets, MVP, 45 minutes of audio at 16 kilohertz transcribes within 1.1X times and 1.5X real time on M-series Mac. Memory under 2 gigabytes under STT. Final refined summary is less than 60 seconds after capture end. Atomic note precision recall, user feedback tool to flag incorrect split links, log correction rate. Core features in UX on the desktop. Obsidian-like workspace, which is going to have a vault sidebar, files, tags and backlinks panel. Voice capture bar, record, pause, stop, live transcription plus live translation lanes, rolling key points. Atomic notes view, it's a card stack with title, statement, context, links, tags. The graph view will be a force directed filter by tag time and source, expand neighbors interaction. Robust search, it's a single box. You can use that as like a multibar or an omnibar similar to Google or chat GPT, which will allow for tag, source, colon, lecture, data, colon, or date, excuse me, colon, greater than equals 2015, tag 10, tag 01, type colon atomic, fuzzy terms and vector find similar. Wikilinks backlinks line will be a double bracket open, double bracket close, auto-suggestions, backlinks panel and context snippets. The export hub, we'll have Obsidian with markdown and front matter plus Wikilinks, lossless format. Notion will be pages via API, so we will utilize a Notion API for that, addings, bullets, backlinks as relations or footers. One note will have graph API pages and sections. Google docs, docs API with headings, footnotes for citations. Dot zip of atomic notes for LMS upload. Cloud, sign in, choose local only versus sync, choose encrypted at rest keys. Accessibility, keyboard first, screen reader labels, WCAG AA. Data models will be simplified. We'll return to that. Storage, local vaults, vault index dot JSON, vault embeddings dot SQLite. The cloud will be super base based, notes, edges, embeddings, PG vector, files and storage, RLS, policies per user or organization. Cloud tier, super base plus for cell, super base, auth, we'll email password, Google workspace, Microsoft single sign on for school districts. I'd like to add Apple single sign on as well. Postgres plus PG vector is semantic search. Storage will be user vault files, audio with RLS. Edge functions, export transformers, background refined jobs. Vercel next JS will be a web companion UI, browsing, read only editing, admin and a billing portal. API routes for signed uploads, URLs, export proxies. The billing will utilize a stripe EDU plans, PO, invoice support, plan tiers. These plan tiers will be free, pro, and then education org. Compliance and policy for a school district, FERPA and COPPA posture, parental consent flows if under the age of 13. Student data segregation, no training on user data. That is critical. DPA template and FERPA addendum, data residency option for the U.S. and EU. Single sign on for Google workspace for education, Microsoft intra ID and SCIM optional. Audit logging, sign ins, exports, admin actions, immutable log table. You have to have a immutable referenceable audit table. Or log book. Access controls, organizational admin roles, vault level permissions. The vault level permissions are for the teacher tier to ensure that students cannot go in and edit or modify notes by the teacher, which would, in effect, have a negative impact on the student experience. Security and at rest encryption for cloud. Optional client side encryption for vaults. Routine backups, incident response run book. Security WCAG 2.1 AA keyboard navigation and captions and subtitles are a must. Okay. That is all at this time. Ending note.

> Transcription meta
> Speaking: 3107.80s
> Recorded: 755.60s